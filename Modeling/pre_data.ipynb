{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "354d3c10",
   "metadata": {},
   "source": [
    "### 结构化数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff71c878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "import torchkeras \n",
    "from torch import nn \n",
    "from torch.utils.data import Dataset,DataLoader,TensorDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988dc175",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = DataLoader(TensorDataset(torch.tensor(x_train).float(),torch.tensor(y_train).float()),\n",
    "                     shuffle = True, batch_size = 8)\n",
    "dl_val = DataLoader(TensorDataset(torch.tensor(x_test).float(),torch.tensor(y_test).float()),\n",
    "                     shuffle = False, batch_size = 8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ed36cf",
   "metadata": {},
   "source": [
    "#### 训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82f8a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from tqdm import tqdm  #时间进度条\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import copy as deepcopy\n",
    "from torchkeras.metrics import Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88b980d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printlog(info):\n",
    "    nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print('\\n'+'========'*8 + '%s'%nowtime)\n",
    "    print(str(info)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66392c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "metrics_dict = {'acc':Accuracy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db5ad12",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "ckpt_path = 'checkpoint.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e8a105",
   "metadata": {},
   "outputs": [],
   "source": [
    "#early stopping相关设置\n",
    "monitor = 'val_acc'\n",
    "patience = 5\n",
    "mode = 'max'\n",
    "\n",
    "history = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c4e8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    printlog(\"Epoch{0}/{1}\".format(epoch+1,epochs))\n",
    "    \n",
    "    #train\n",
    "    model.train()\n",
    "    \n",
    "    total_loss,step = 0,0\n",
    "    loop = tqdm(enumerate(dl_train), total=len(dl_train))\n",
    "    train_metrics_dict = deepcopy(metrics_dict) #deepcopy深度复制一个对象\n",
    "    \n",
    "    for i,data in loop:\n",
    "        inputs,labels = data\n",
    "        #forward\n",
    "        preds = model(inputs)\n",
    "        loss = criterion(preds,labels)\n",
    "        #backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        #update\n",
    "        optimizer.step()\n",
    "        \n",
    "        #metrics\n",
    "        step_metrics = {\"train_\"+name: metric_fn(preds,labels).item()\n",
    "                       for name,metric_fn in train_metrics_dict.item()}\n",
    "        \n",
    "        step_log = dict({\"train_loss\":loss.item()}, **step_metrics) #**表示传入字典\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        step += 1\n",
    "        if i!=len(dl_train)-1:\n",
    "            loop.set_postfix(**step_log)  #set_postfix动态进度条\n",
    "        else:\n",
    "            epoch_loss = total_loss/step\n",
    "            epoch_metrics = {\"train_\"+name:metric_fn.compute().items()\n",
    "                            for name,metric_fn in train_metrics_dict.items()}\n",
    "            epoch_log = dict({\"train_loss\":epoch_loss},**epoch_metrics)\n",
    "            loop.set_postfix(**epoch_log)\n",
    "            \n",
    "            for name,metric_fn in train_metrics_dict.items():\n",
    "                metric_fn.reset() #用完恢复默认\n",
    "                \n",
    "    for name, metric in epoch_log.items():\n",
    "        history[name] = history.get(name, []) + [metric]\n",
    "        \n",
    "    #validation\n",
    "    model.eval()\n",
    "    \n",
    "    total_loss,step = 0,0\n",
    "    loop = tqdm(enumerate(dl_val), total = len(dl_val))\n",
    "    \n",
    "    val_metrics_dict = deepcopy(metrics_dict)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i,data in loop:\n",
    "            \n",
    "            inputs,labels = data\n",
    "            \n",
    "            #forward\n",
    "            preds = model(inputs)\n",
    "            loss = criterion(preds,labels)\n",
    "            \n",
    "            #metrics\n",
    "            step_metrics = {\"val_\"+name:metric_fn(preds,labels).items()\n",
    "                           for name,metric_fn in val_metrics_dict.items()}\n",
    "            step_log = dict({\"val_loss\":loss.items()},**step_metrics)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            step += 1\n",
    "            if i!=len(dl_val)-1:\n",
    "                loop.set_postfix(**step_log)\n",
    "            else:\n",
    "                epoch_loss = total_loss/step\n",
    "                epoch_metrics = {\"val_\"+name:metric_fn.compute().item() \n",
    "                                 for name,metric_fn in val_metrics_dict.items()}\n",
    "                epoch_log = dict({\"val_loss\":epoch_loss},**epoch_metrics)\n",
    "                loop.set_postfix(**epoch_log)\n",
    "\n",
    "                for name,metric_fn in val_metrics_dict.items():\n",
    "                    metric_fn.reset()\n",
    "    epoch_log[\"epoch\"] = epoch\n",
    "    for name, metric in epoch_log.items():\n",
    "        history[name] = history.get(name, []) + [metric]\n",
    "        \n",
    "    #early_stopping\n",
    "    arr_scores = history[monitor]\n",
    "    best_score_idx = np.argmax(arr_scores) if mod=='max' else np.argmin(arr_scores)\n",
    "    if best_score_idx == len(arr_scores)-1:\n",
    "        torch.save(model.state_dict(),ckpt_path)\n",
    "        print(\"<<<<<< reach best {0} : {1} >>>>>>\".format(monitor,\n",
    "             arr_scores[best_score_idx]),file=sys.stderr)\n",
    "    if len(arr_scores)-best_score_idx > patience:\n",
    "        print(\"<<<<<< {} without improvement in {} epoch, early stopping >>>>>>\".format(\n",
    "            monitor,patience),file=sys.stderr)\n",
    "        break\n",
    "    model.load_state_dict(torch.load(ckpt_path))\n",
    "    \n",
    "dfhistory = pd.DataFrame(history)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1f16f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_metric(dfhistory, metric):\n",
    "    train_metrics = dfhistory[\"train_\"+metric]\n",
    "    val_metrics = dfhistory['val_'+metric]\n",
    "    epochs = range(1, len(train_metrics) + 1)\n",
    "    plt.plot(epochs, train_metrics, 'bo--')\n",
    "    plt.plot(epochs, val_metrics, 'ro-')\n",
    "    plt.title('Training and validation '+ metric)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([\"train_\"+metric, 'val_'+metric])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd60ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(dfhistory,\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4af46b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(dfhistory,\"acc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6204fc23",
   "metadata": {},
   "source": [
    "### 使用模型\n",
    "通过调用pickle序列化方法实现的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2d9fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(torch.tensor(x_test[0:10]).float())\n",
    "y_pred_probs = torch.sigmoid(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7acb850",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = torch.where(y_pred_probs>0.5,  #可以修改阈值\n",
    "                     torch.ones_like(y_pred_probs),torch.zeros_like(y_pred_probs))\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2418fef",
   "metadata": {},
   "source": [
    "### 保存模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25520ef7",
   "metadata": {},
   "source": [
    "#### 1、保存模型参数（推荐）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918102a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98a8768",
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存模型参数\n",
    "torch.save(model.state_dict(),\"model_parameter.pt\")\n",
    "model_clone = create_model()\n",
    "model_loaded = torch.load(\"model_parameter.pt\")\n",
    "model_clone.load_state_dict(model_loaded)\n",
    "\n",
    "torch.sigmoid(model_clone.forward(torch.tensor(x_test[0:10]).float()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19535f14",
   "metadata": {},
   "source": [
    "#### 2、保存完整模型（不推荐）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8227139",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"mymodel.pt\")\n",
    "model_loaded = torch.load(\"mymodel.pt\")\n",
    "torch.sigmoid(model_loaded(torch.tensor(x_test[0:10]).float())).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6009cbd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86c72de6",
   "metadata": {},
   "source": [
    "### 图片数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4bea60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision import transforms as T\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06ab343",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_img = T.Compose([T.ToTensor()])\n",
    "\n",
    "def transform_label(x):\n",
    "    return torch.tensor([x]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae91ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = datasets.ImageFolder(\"./eat_pytorch_datasets/cifar2/train/\",\n",
    "                               transform = transform_img,target_transform = transform_label)\n",
    "\n",
    "ds_val = datasets.ImageFolder(\"./eat_pytorch_datasets/cifar2/test/\",\n",
    "                             transform = transform_img,target_transform = transform_label)\n",
    "print(ds_train.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699b0aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = DataLoader(ds_train,\n",
    "                      batch_size=50,\n",
    "                     shuffle=True)\n",
    "dl_val  = DataLoader(ds_val,\n",
    "                    batch_size=50,\n",
    "                    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c7c805",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.figure(figsize=(8,8))\n",
    "for i in range(9):\n",
    "    img,label = ds_train[i]\n",
    "    img = img.permute(1,2,0)\n",
    "    ax = plt.subplot(3,3,i+1)\n",
    "    ax.imshow(img.numpy())\n",
    "    ax.set_title(\"label = %d\"%label.item())\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fc75ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for features,labels in dl_train:\n",
    "    print(features.shape,label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63470f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3,out_channels=32,kernel_size=3)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32,out_channels=64,kernel_size=5)\n",
    "        self.dropout = nn.Dropout2d(p=0.2)\n",
    "        self.adaptive_pool = nn.AdaptiveMaxPool2d((1,1))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear = nn.Linear(64,32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(32,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.con2v(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.adaptive_pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "    \n",
    "model = Net()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1223de0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee31ac8f",
   "metadata": {},
   "source": [
    "### 文本数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e58b4a",
   "metadata": {},
   "source": [
    "文本数据预处理较为繁琐，包括文本切词，构建词典，编码转换，序列填充，构建数据管道等等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdaa7029",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader,TensorDataset\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2fa959a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "minfreq = 30 #仅考虑词频超过30的词\n",
    "maxlen = 200  #每个样本保留200个词的长度\n",
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9b6ca68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"/Users/hwangsheep/PycharmProjects/torch_test/starting/eat_pytorch_datasets 2/imdb/train.tsv\",\n",
    "                       sep=\"\\t\",\n",
    "                       header = None,\n",
    "                       names = [\"label\",\"text\"])\n",
    "df_val = pd.read_csv(\"/Users/hwangsheep/PycharmProjects/torch_test/starting/eat_pytorch_datasets 2/imdb/test.tsv\",\n",
    "                       sep=\"\\t\",\n",
    "                       header = None,\n",
    "                       names = [\"label\",\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed4394fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       label                                               text\n",
      "0          0  It really boggles my mind when someone comes a...\n",
      "1          0  Mary Pickford becomes the chieftain of a Scott...\n",
      "2          0  Well, at least my theater group did, lol. So o...\n",
      "3          1  I must give How She Move a near-perfect rating...\n",
      "4          0  I must say, when I read the storyline on the b...\n",
      "...      ...                                                ...\n",
      "19995      1  Simple, meaningful and delivers an emotional p...\n",
      "19996      1  I'm fan of ART, I like anything about Art, I l...\n",
      "19997      0  Despite being a sequel to the more potent orig...\n",
      "19998      0  Also known in a different form as \"House of Ex...\n",
      "19999      0  This has the absolute worst performance from R...\n",
      "\n",
      "[20000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70c32f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#文本切词\n",
    "tokenizer = get_tokenizer('basic_english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b88b2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#构建词典\n",
    "pad_idx,unk_idx = 0,1\n",
    "special_symbols = ['<pad>','<unk']\n",
    "\n",
    "#yield就是return返回一个值，并且记住这个返回的位置，下次迭代就从这个位置后(下一行)开始\n",
    "def yield_tokens(dfdata):  \n",
    "    for text in dfdata['text']:\n",
    "        yield tokenizer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4246bece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object yield_tokens at 0x7fc53800e740>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yield_tokens(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d497c16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size = 8813\n"
     ]
    }
   ],
   "source": [
    "#vocab对象，将每个词映射成对应数字\n",
    "\n",
    "vocab = build_vocab_from_iterator(\n",
    "    yield_tokens(df_train),\n",
    "    min_freq = minfreq,\n",
    "    specials = special_symbols,\n",
    "    special_first=True)\n",
    "\n",
    "#text_pipeline = lambda x : vocab(tokenizer(x))\n",
    "\n",
    "vocab.set_default_index(unk_idx)\n",
    "vocab_size = len(vocab)\n",
    "print(\"vocab_size = \"+str(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2730134e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab.get_itos():\n",
      " ['<pad>', '<unk', 'the', '.', ',', 'and', 'a', 'of', 'to', \"'\", 'is', 'it', 'in', 'i', 'this', 'that', 's', 'was', 'as', 'for']\n",
      "vocab.get_stoi()['<pad>']:\n",
      " 0\n"
     ]
    }
   ],
   "source": [
    "#查看词典前20个词\n",
    "#itos:index to string 查看字典(列表形式)\n",
    "\n",
    "#stoi:string to index 查看词典(字典形式)\n",
    "print(\"vocab.get_itos():\\n\",vocab.get_itos()[:20])\n",
    "print(\"vocab.get_stoi()['<pad>']:\\n\",vocab.get_stoi()['<pad>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd7f2b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#序列填充\n",
    "def pad(seq,max_length,pad_value=0):\n",
    "    n = len(seq)\n",
    "    result = seq + [pad_value]*(max_length-n)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b785f6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "#编码转换\n",
    "def text_pipeline(text):\n",
    "    words = tokenizer(text)\n",
    "    tokens = vocab(words)\n",
    "    result = pad(tokens,maxlen,pad_idx)\n",
    "    return result\n",
    "\n",
    "print(len(text_pipeline('this is an example')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbcdab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#构建管道\n",
    "class ImdbDataset(Dataset):\n",
    "    def __init__(self,df):\n",
    "        self.df = df\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self,index):\n",
    "        text = self.df[\"text\"].iloc[index]\n",
    "        tokens = torch.tensor(text_pipeline(text)).int()\n",
    "        label = torch.tensor([self.df['label'].iloc[index]]).float()\n",
    "        return tokens,label\n",
    "    \n",
    "ds_train = ImdbDataset(df_train)\n",
    "ds_val = ImdbDataset(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a16f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = DataLoader(ds_train,\n",
    "                     batch_size=50,\n",
    "                     shuffle=True)\n",
    "dl_val = DataLoader(ds_val,\n",
    "                   batch_size=50,\n",
    "                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9d73329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fc561a60970>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn \n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82acb2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_embeddings = vocab_size,embedding_dim=3,padding_idx=0)\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=3,out_channels=16,kernel_size=5),\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(in_channels=16,out_channels=128,kernel_size=2),\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(6144,1)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.embedding(x).transpose(1,2)\n",
    "        x = self.conv(x)\n",
    "        y = self.dense(x)\n",
    "        return y\n",
    "    \n",
    "net = Net()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c04f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchkeras import summary\n",
    "summary(net,input_shape=(3,32,32))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
